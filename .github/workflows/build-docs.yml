---
# Workflow to build the documentation.
#
# - validate CITATION.CFF file
# - check the quality of the doc strings
# - get datasets from cache or from source
# - build doc and upload it as artifact
# - on `main` (or on github release): trigger hosting of dev (or stable) doc on https://github.com/nilearn//nilearn.github.io.git
#
# .. admonition:: Control via commit message
#    :class: tip
#
#    This workflow can be controlled if your commit message contains:
#
#    - ``[full doc]`` runs a full build on pull-request.
#    - ``[skip doc]`` skip build of the documentation.
#    - ``[example] name_of_example.py`` trigger build of some specific examples.
#    - ``[force download]`` do not rely of cached datasets and force to redownload them.
#
# On Pull Requests, "partial builds" are run by default which render all the rst files,
# but only build examples modified in the Pull Request.
# This saves a lot of time and resources when working on Pull Requests.
#
# Occasionally, some changes necessitate rebuilding the documentation from scratch,
# for example to see the full effect of the changes.
# These are called "full builds".
#
# You can request a full build from a Pull Request at any time by including the tag ``[full doc]`` in your commit message.
# Note that this will trigger a full build of the documentation which usually takes >90 minutes.
#
# .. code-block:: bash
#
#   $ git commit -m "[full doc] request full build"
#
# Full builds are always run on "main".
# This is done every time there is a push on "main" and every week.
#
# Most of this workflow is skipped if ``[skip doc]`` is in the commit message.
#
# Though partial builds will build modified examples,
# sometimes code changes on the module side could affect the plots in unmodified examples.
# For this, you can request for the CI to build a specific example
# by using the tag ``[example]`` and the name of the example.
# This is useful when wanting to get quick feedback from reviewers.
#
# .. code-block:: bash
#
#   $ git commit -m "[example] plot_nilearn_101.py"
#
# However for quick checks to do yourself
# you should always opt for local builds following the instructions here:
# in the :ref:`building documentation` section.
#
# Dataset caching
# """""""""""""""
#
# We also implemented a dataset caching strategy within this workflow such that datasets are only downloaded once every month.
# Once these datasets are cached,
# they will be used by all jobs running without requiring any download.
# This saves a lot of time and avoids potential network errors that can happen
# when downloading datasets from remote servers.
#
# Data is cached after the ``get_data`` job to be passed to the ``build_docs`` job.
# Data can be cached and restored across attempts of a run of this workflow.
# Data can be cached and restored across run of this workflow.
#
# Note that you can request to download all datasets and ignore the cache at any time
# by including the tag ``[force download]`` in your commit message.
#
# To run a full build and download all datasets, you would then combine both tags:
#
# .. code-block:: bash
#
#   $ git commit -m "[full doc][force download] request full build"
###
name: DocumentationBuilder

on:
    push:
        branches:
        -   main
    pull_request:
        branches:
        -   '*'
    schedule:
    # Run every Monday at 8am UTC
    -   cron: 0 8 * * 1

    # Allows you to run this workflow manually from the Actions tab
    workflow_dispatch:

    # This will run automatically when a release is published
    release:
        types: [published]

concurrency:
    group: ${{ github.workflow }}-${{ github.ref }}
    cancel-in-progress: true

env:
    # Force to use color
    FORCE_COLOR: true
    BROWSER: /usr/bin/firefox
    DISPLAY: :99.0
    NILEARN_DATA: /home/runner/work/nilearn/nilearn/nilearn_data
    MIN_PYTHON_VERSION: '3.9'
    HEAD_COMMIT_MESSAGE: ${{ github.event.head_commit.message }}

jobs:

    # Make citation metadata from CITATION.cff is valid.
    # as it is used in the documentation build.
    validate_cff:
        runs-on: ubuntu-latest
        steps:
        -   name: Checkout nilearn
            uses: actions/checkout@v4

        -   name: Check whether the citation metadata from CITATION.cff is valid
            uses: citation-file-format/cffconvert-github-action@2.0.0
            with:
                args: --validate

    quality_control:
        # run a couple of scripts to check quality of the docstrings
        runs-on: ubuntu-latest
        steps:
        -   name: Checkout nilearn
            uses: actions/checkout@v4
        -   name: Install the latest version of uv
            uses: astral-sh/setup-uv@v6
        -   uses: actions/setup-python@v5
            with:
                python-version: ${{ env.MIN_PYTHON_VERSION }}
        -   name: Install tox
            run: uv tool install tox --with=tox-uv --with=tox-gh-actions
        -   name: Show tox config
            run: tox c
        -   name: Check doc strings
            run: |
                tox run \
                    --colored yes \
                    --list-dependencies \
                    -e doc_qc

    check_skip_flags:
        name: Check skip flags
        runs-on: ubuntu-latest
        steps:
        -   name: Get repo
            uses: actions/checkout@v4
            with:
                ref: ${{ github.event.pull_request.head.sha }}
        -   name: Check head git commit message
            run: |
                headCommitMsg=$(git show -s --format=%s)
                if [[ $headCommitMsg == *"[skip doc]"* ]]; then
                    echo "skipping doc build"
                    exit 1
                fi

    # Check the build type and files examples to generate
    # Upload as an artifact for other jobs.
    build_type:
        needs: [check_skip_flags, validate_cff]
        runs-on: ubuntu-latest
        steps:
        -   name: Checkout nilearn
            uses: actions/checkout@v4
            with:
                # If pull request, checkout HEAD commit with all commit history
                ref: ${{ github.event.pull_request.head.sha }}
                fetch-depth: 0
        -   name: Merge with upstream
            run: ./build_tools/github/merge_upstream.sh
        -   name: Check if we are doing a full or partial build
            run: ./build_tools/github/build_type.sh
            env:
                COMMIT_SHA: ${{ github.event.pull_request.head.sha }}
        -   name: Verify build type
            run: |
                echo "PATTERN = $(cat pattern.txt)"
                echo "BUILD = $(cat build.txt)"
        -   name: Upload build.txt and pattern.txt
            uses: actions/upload-artifact@v4
            with:
                name: build_type
                path: |
                    build.txt
                    pattern.txt
                retention-days: 1
                overwrite: true

    get_data:
        # This prevents this workflow from running on a fork.
        # To test this workflow on a fork, uncomment the following line.
        if: github.repository == 'nilearn/nilearn'
        needs: [build_type]
        runs-on: ubuntu-latest
        defaults:
            run:
                shell: bash -el {0}

        steps:
        -   name: Checkout nilearn
            uses: actions/checkout@v4
            with:
                # If pull request, checkout HEAD commit with all commit history
                ref: ${{ github.event.pull_request.head.sha }}
                fetch-depth: 0

        # Set up environment
        -   name: Setup python
            uses: actions/setup-python@v5
            with:
                python-version: ${{ env.MIN_PYTHON_VERSION }}

        -   name: Install packages
            run: |
                python -m pip install --user --upgrade pip setuptools
                python -m pip install .

        -   name: Download build type
            uses: actions/download-artifact@v4
            with:
                name: build_type
        -   name: Verify build type
            id: build-type
            run: echo "build=$(cat build.txt)" >> $GITHUB_OUTPUT

        -   name: Determine if we will use cached data
            run: ./build_tools/github/determine_restore_data.sh
        -   name: Get cache key
            id: cache-key
            run: |
                if [[ $(cat restore.txt) == "true" ]]; then
                    echo "restore=true" >> $GITHUB_OUTPUT
                fi

        -   name: Key for cache based on month number
            run: date +%m > month_num;

        -   name: Get cache from a previous attempts on this PR or branch
            if: steps.cache-key.outputs.restore == 'true'
            id: restore-previous-run
            uses: actions/cache/restore@v4
            with:
                path: nilearn_data
                key: data_cache-${{ github.workflow }}_ref-${{ github.ref }}_run-${{ github.run_number }}_attempt-${{ github.run_attempt }}
                restore-keys: |
                    data_cache-${{ github.workflow }}_ref-${{ github.ref }}_run-${{ github.run_number }}
                    data_cache-${{ github.workflow }}_ref-${{ github.ref }}

        -   name: Get data from a previous successful run for full builds
            # only run it if we did not get the data from a previous attempt
            if: ${{ steps.build-type.outputs.build == 'html-strict' && steps.cache-key.outputs.restore == 'true' && steps.restore-previous-run.outputs.cache-hit
                != 'true' }}
            id: restore-previous-full-build
            uses: actions/cache@v4
            with:
                path: nilearn_data
                key: data_cache-${{ github.workflow }}_month-${{ hashFiles('month_num') }}

        -   name: Get data for reports from a previous successful run
            # only run it if we did not get the data from a previous attempt
            if: ${{ steps.cache-key.outputs.restore == 'true' && steps.restore-previous-run.outputs.cache-hit != 'true' && steps.restore-previous-full-build.outputs.cache-hit
                != 'true' }}
            uses: actions/cache@v4
            with:
                path: |
                    nilearn_data/adhd
                    nilearn_data/development_fmri
                    nilearn_data/difumo_atlases
                    nilearn_data/ds000030
                    nilearn_data/fiac_nilearn.glm
                    nilearn_data/icbm152_2009
                    nilearn_data/miyawaki2008
                    nilearn_data/msdl_atlas
                    nilearn_data/oasis1
                    nilearn_data/schaefer_2018
                    nilearn_data/yeo_2011

                key: data_cache-${{ github.workflow }}_month-${{ hashFiles('month_num') }}

        -   name: Get data
            run: |
                echo "Download data required for building reports in doc"
                python doc/get_data_examples.py

                echo "Download data required for this doc build type"
                BUILD_TYPE=$(cat build.txt)
                python doc/get_data_examples.py $BUILD_TYPE

        -   name: Save cache to pass to build_docs job
            uses: actions/cache/save@v4
            if: always()
            with:
                path: nilearn_data
                key: data_cache-${{ github.workflow }}_ref-${{ github.ref }}_run-${{ github.run_number }}_attempt-${{ github.run_attempt }}

    # Steps to build the documentation.
    build_docs:
        needs: [get_data]
        # This prevents this workflow from running on a fork.
        # To test this workflow on a fork, uncomment the following line.
        runs-on: ubuntu-latest
        defaults:
            run:
                shell: bash -el {0}

        steps:
        -   name: Checkout nilearn
            uses: actions/checkout@v4
            with:
        # If pull request, checkout HEAD commit with all commit history
                ref: ${{ github.event.pull_request.head.sha }}
                fetch-depth: 0
        -   name: Merge with upstream
            run: ./build_tools/github/merge_upstream.sh

        # Set up environment
        -   name: Install apt packages
            run: |
                sudo -E apt-get -yq update
                sudo -E apt-get -yq --no-install-suggests --no-install-recommends install \
                    dvipng texlive-latex-base texlive-latex-extra

        -   name: Key for cache based on month number
            run: date +%m > month_num;

        -   name: Get data from the get_data job
            uses: actions/cache@v4
            with:
                path: nilearn_data
                key: data_cache-${{ github.workflow }}_ref-${{ github.ref }}_run-${{ github.run_number }}_attempt-${{ github.run_attempt }}
                restore-keys: |
                    data_cache-${{ github.workflow }}_ref-${{ github.ref }}_run-${{ github.run_number }}

        # Set up and launch a virtual browser needed for one example to run
        # without stalling the job. The example launches an html in the browser.
        -   name: Set up display server for virtual browser
            run: Xvfb -ac :99 -screen 0 1280x1024x16 > /dev/null 2>&1 &

        -   name: Install the latest version of uv
            uses: astral-sh/setup-uv@v6

        -   name: Setup python
            uses: actions/setup-python@v5
            with:
                python-version: ${{ env.MIN_PYTHON_VERSION }}

        -   name: Download build type
            uses: actions/download-artifact@v4
            with:
                name: build_type

        -   name: Install tox
            run: uv tool install tox --with=tox-uv --with=tox-gh-actions

        -   name: Show tox config
            run: tox c

        # Run the doc build
        # We let tox handle creating virtual env and install dependencies.
        # If no data is restored in previous steps,
        # the data will be downloaded during the build
        # (this only applies for full builds;
        # no data is downloaded for partial builds).
        -   name: Build docs
            id: build-docs
            run: |
                set -o pipefail;
                export PATTERN=$(cat pattern.txt)
                tox run \
                    --colored yes \
                    --list-dependencies \
                    -e doc -- $(cat build.txt) 2>&1 | tee log.txt;

        -   name: Check for unreplaced argument in docstrings
            if: always()
            run: |
                ./build_tools/github/fill_doc_check.sh
                cat doc/tmp/doc_check.txt

        -   name: Check warnings in doc
            if: always()
            run: |
                ./build_tools/github/warning_in_doc_check.sh

        -   name: Upload doc checks
            if: always()
            uses: actions/upload-artifact@v4
            with:
                name: doc_checks
                path: doc/tmp

        -   name: Upload documentation
            if: steps.build-docs.outcome == 'success'
            uses: actions/upload-artifact@v4
            with:
                name: doc
                path: doc/_build/html

    deploy_on_main:
        runs-on: ubuntu-latest
        needs: [build_docs]
        if: ${{ contains(fromJSON('["push", "workflow_dispatch", "schedule", "release"]'), github.event_name)}}
        steps:
        -   name: Checkout nilearn
            uses: actions/checkout@v4
            with:
                fetch-depth: 0

        -   name: Add SSH key
            env:
                SSH_AUTH_SOCK: /tmp/ssh_agent.sock
            run: |
                mkdir -p ~/.ssh
                ssh-keyscan github.com >> ~/.ssh/known_hosts
                echo "${{ secrets.ACTIONS_SSH_DEPLOY }}" > ~/.ssh/github_actions
                chmod 600 ~/.ssh/github_actions
                ssh-agent -a $SSH_AUTH_SOCK > /dev/null
                ssh-add ~/.ssh/github_actions

        -   uses: actions/download-artifact@v4
            with:
                name: doc
                path: doc/_build/html

        -   name: Identify deploy type
            id: deploy-type
            run: |
                if ${{ contains(fromJSON('["release"]'), github.event_name)}}; then
                    echo "DEPLOY_TYPE=stable" >> $GITHUB_OUTPUT
                else
                    echo "DEPLOY_TYPE=dev" >> $GITHUB_OUTPUT
                fi

        -   name: deploy
            env:
                SSH_AUTH_SOCK: /tmp/ssh_agent.sock
                COMMIT_SHA: ${{ github.event.head_commit.id }}
                DEPLOY_TYPE: ${{ steps.deploy-type.outputs.DEPLOY_TYPE }}
            run: |
                git config --global user.email "actions@github.com"
                git config --global user.name "GitHub actions"
                ./build_tools/github/deploy_doc.sh
