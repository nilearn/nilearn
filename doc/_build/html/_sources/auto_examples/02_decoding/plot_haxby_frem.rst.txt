
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/02_decoding/plot_haxby_frem.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_02_decoding_plot_haxby_frem.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_02_decoding_plot_haxby_frem.py:


Decoding with FREM: face vs house object recognition
=========================================================

This example uses fast ensembling of regularized models (FREM) to decode
a face vs house discrimination task from Haxby 2001 study. FREM uses an
implicit spatial regularization through fast clustering and aggregates a
high number of estimators trained on various splits of the training set,
thus returning a very robust decoder at a lower computational cost than
other spatially regularized methods.

To have more details, see: :ref:`frem`.

.. GENERATED FROM PYTHON SOURCE LINES 16-18

Load the Haxby dataset
------------------------

.. GENERATED FROM PYTHON SOURCE LINES 18-48

.. code-block:: default

    from nilearn.datasets import fetch_haxby
    data_files = fetch_haxby()

    # Load behavioral data
    import pandas as pd
    behavioral = pd.read_csv(data_files.session_target[0], sep=" ")

    # Restrict to face and house conditions
    conditions = behavioral['labels']
    condition_mask = conditions.isin(['face', 'house'])

    # Split data into train and test samples, using the chunks
    condition_mask_train = (condition_mask) & (behavioral['chunks'] <= 6)
    condition_mask_test = (condition_mask) & (behavioral['chunks'] > 6)

    # Apply this sample mask to X (fMRI data) and y (behavioral labels)
    # Because the data is in one single large 4D image, we need to use
    # index_img to do the split easily
    from nilearn.image import index_img
    func_filenames = data_files.func[0]
    X_train = index_img(func_filenames, condition_mask_train)
    X_test = index_img(func_filenames, condition_mask_test)
    y_train = conditions[condition_mask_train].values
    y_test = conditions[condition_mask_test].values


    # Compute the mean epi to be used for the background of the plotting
    from nilearn.image import mean_img
    background_img = mean_img(func_filenames)


.. GENERATED FROM PYTHON SOURCE LINES 49-51

Fit FREM
--------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 51-59

.. code-block:: default

    from nilearn.decoding import FREMClassifier
    decoder = FREMClassifier(cv=10)
    # Fit model on train data and predict on test data
    decoder.fit(X_train, y_train)
    y_pred = decoder.predict(X_test)
    accuracy = (y_pred == y_test).mean() * 100.
    print("FREM classification accuracy : %g%%" % accuracy)


.. GENERATED FROM PYTHON SOURCE LINES 60-62

Visualization of FREM weights
------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 62-67

.. code-block:: default

    from nilearn import plotting
    plotting.plot_stat_map(decoder.coef_img_["face"], background_img,
                           title="FREM: accuracy %g%%, 'face coefs'" % accuracy,
                           cut_coords=(-52, -5), display_mode="yz")
    plotting.show()

.. GENERATED FROM PYTHON SOURCE LINES 68-74

FREM ensembling procedure yields an important improvement of decoding
accuracy on this simple example compared to fitting only one model per
fold and the clustering mechanism keeps its computational cost reasonable
even on heavier examples. Here we ensembled several instances of l2-SVC,
but FREMClassifier also works with ridge or logistic.
FREMRegressor object is also available to solve regression problems.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)

**Estimated memory usage:**  0 MB


.. _sphx_glr_download_auto_examples_02_decoding_plot_haxby_frem.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/02_decoding/plot_haxby_frem.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_haxby_frem.py <plot_haxby_frem.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_haxby_frem.ipynb <plot_haxby_frem.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
