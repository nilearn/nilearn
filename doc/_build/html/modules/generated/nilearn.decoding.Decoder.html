<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="nilearn.decoding.Decoder" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://nilearn.github.io/modules/generated/nilearn.decoding.Decoder.html" />
  
<meta property="og:site_name" content="Nilearn" />
  
<meta property="og:description" content="Examples using nilearn.decoding.Decoder: A introduction tutorial to fMRI decoding A introduction tutorial to fMRI decoding Decoding with ANOVA + SVM: face vs house in the Haxby dataset Decoding wit..." />
  
<meta property="og:image" content="https://nilearn.github.io/_images/sphx_glr_plot_decoding_tutorial_thumb.png" />
  
<meta property="og:image:alt" content="A introduction tutorial to fMRI decoding" />
  <link rel="search" title="Search" href="../../search.html" /><link rel="next" title="nilearn.decoding.DecoderRegressor" href="nilearn.decoding.DecoderRegressor.html" /><link rel="prev" title="nilearn.decoding: Decoding" href="../decoding.html" />

    <link rel="shortcut icon" href="../../_static/favicon.ico"/><meta name="generator" content="sphinx-5.1.1, furo 2022.06.21"/>
        <title>nilearn.decoding.Decoder - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=40978830699223671f4072448e654b5958f38b89" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  --admonition-font-size: 100%;
  --admonition-title-font-size: 100%;
  --color-announcement-background: #FBB360;
  --color-announcement-text: #111418;
  --color-admonition-title--note: #448aff;
  --color-admonition-title-background--note: #448aff10;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<div class="announcement">
  <aside class="announcement-content">
     <p>This is the development documentation of nilearn (0.10.1.dev) <a class="sd-sphinx-override sd-badge sd-text-wrap sd-btn-outline-dark reference external" href="https://nilearn.github.io"><span>Switch to stable version (0.10.0)</span></a></p> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../auto_examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/00_tutorials/index.html">Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/01_plotting/index.html">Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_colormaps.html">Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/02_decoding/index.html">Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/03_connectivity/index.html">Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using dictionary learning and functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/04_glm_first_level/index.html">GLM: First level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fixed_effects.html">Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fiac_analysis.html">Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/05_glm_second_level/index.html">GLM: Second level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_oasis.html">Voxel-Based Morphometry on OASIS dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_association_test.html">Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/06_manipulating_images/index.html">Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/07_advanced/index.html">Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/07_advanced/plot_beta_series.html">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../user_guide.html">User guide</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html">1. Introduction</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../decoding/index.html">2. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/decoding_intro.html">2.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/estimator_choice.html">2.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/frem.html">2.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/space_net.html">2.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/searchlight.html">2.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/going_further.html">2.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../connectivity/index.html">3. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/functional_connectomes.html">3.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../connectivity/connectome_extraction.html">3.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../developers/group_sparse_covariance.html">3.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/resting_state_networks.html">3.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/region_extraction.html">3.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/parcellating.html">3.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../plotting/index.html">4. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../glm/index.html">5. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../glm/glm_intro.html">5.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/first_level_model.html">5.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/second_level_model.html">5.3. Second level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../manipulating_images/index.html">6. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/input_output.html">6.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/manipulating_images.html">6.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/masker_objects.html">6.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../building_blocks/index.html">7. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/manual_pipeline.html">7.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/neurovault.html">7.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">API References</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_bids_langloc_dataset.html">nilearn.datasets.fetch_bids_langloc_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_ds000030_urls.html">nilearn.datasets.fetch_ds000030_urls</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_openneuro_dataset_index.html">nilearn.datasets.fetch_openneuro_dataset_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_mixed_gambles.html">nilearn.datasets.fetch_mixed_gambles</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="../decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.interfaces.bids.get_bids_files.html">nilearn.interfaces.bids.get_bids_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.interfaces.bids.parse_bids_filename.html">nilearn.interfaces.bids.parse_bids_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.interfaces.bids.save_glm_to_bids.html">nilearn.interfaces.bids.save_glm_to_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.interfaces.fsl.get_design_from_fslmat.html">nilearn.interfaces.fsl.get_design_from_fslmat</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../maskers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.BaseMasker.html">nilearn.maskers.BaseMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.NiftiMasker.html">nilearn.maskers.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.MultiNiftiMasker.html">nilearn.maskers.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.NiftiLabelsMasker.html">nilearn.maskers.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.MultiNiftiLabelsMasker.html">nilearn.maskers.MultiNiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.NiftiMapsMasker.html">nilearn.maskers.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.MultiNiftiMapsMasker.html">nilearn.maskers.MultiNiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.maskers.NiftiSpheresMasker.html">nilearn.maskers.NiftiSpheresMasker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_img_comparison.html">nilearn.plotting.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.recursive_neighbor_agglomeration.html">nilearn.regions.recursive_neighbor_agglomeration</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.regions.HierarchicalKMeans.html">nilearn.regions.HierarchicalKMeans</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.reporting.HTMLReport.html">nilearn.reporting.HTMLReport</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<section id="nilearn-decoding-decoder">
<h1>nilearn.decoding.Decoder<a class="headerlink" href="#nilearn-decoding-decoder" title="Permalink to this heading">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nilearn.decoding.</span></span><span class="sig-name descname"><span class="pre">Decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'svc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">screening_percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'roc_auc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing_fwhm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">standardize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'background'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3109b060e/nilearn/decoding/decoder.py#L775"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.decoding.Decoder" title="Permalink to this definition">#</a></dt>
<dd><p>A wrapper for popular classification strategies in neuroimaging.</p>
<p>The <cite>Decoder</cite> object supports classification methods.
It implements a model selection scheme that averages the best models
within a cross validation loop. The resulting average model is the
one used as a classifier. This object also leverages the`NiftiMaskers` to
provide a direct interface with the Nifti files on disk.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>estimator: str, optional</strong></dt><dd><p>The estimator to choose among:</p>
<blockquote>
<div><ul>
<li><dl>
<dt><cite>svc</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">Linear support vector classifier</a> with L2 penalty.</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">svc</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="mf">1e4</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>svc_l2</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">Linear support vector classifier</a> with L2 penalty.</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Same as option <cite>svc</cite>.</p>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>svc_l1</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">Linear support vector classifier</a> with L1 penalty.</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">svc_l1</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span>
                   <span class="n">dual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">max_iter</span><span class="o">=</span><span class="mf">1e4</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>logistic</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">Logistic regression</a> with L2 penalty.</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logistic</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>
                              <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>logistic_l1</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">Logistic regression</a> with L1 penalty.</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logistic_l1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span>
                                 <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>logistic_l2</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">Logistic regression</a> with L2 penalty</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>Same as option <cite>logistic</cite>.</p>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>ridge_classifier</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html">Ridge classifier</a>.</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ridge_classifier</span> <span class="o">=</span> <span class="n">RidgeClassifierCV</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>dummy_classifier</cite>: <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html">Dummy classifier with stratified strategy</a>.</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;stratified&#39;</span><span class="p">,</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>Default ‘svc’.</p>
</dd>
<dt><strong>mask: filename, Nifti1Image, NiftiMasker, or MultiNiftiMasker, optional</strong></dt><dd><p>Mask to be used on data. If an instance of masker is passed,
then its mask and parameters will be used. If no mask is given, mask
will be computed automatically from provided images by an inbuilt
masker with default parameters. Refer to NiftiMasker or
MultiNiftiMasker to check for default parameters. Default None</p>
</dd>
<dt><strong>cv: cross-validation generator or int, optional (default 10)</strong></dt><dd><p>A cross-validation generator.
See: <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html">https://scikit-learn.org/stable/modules/cross_validation.html</a></p>
</dd>
<dt><strong>param_grid: dict of str to sequence, or sequence of such. Default None</strong></dt><dd><p>The parameter grid to explore, as a dictionary mapping estimator
parameters to sequences of allowed values.</p>
<p>None or an empty dict signifies default parameters.</p>
<p>A sequence of dicts signifies a sequence of grids to search, and is
useful to avoid exploring parameter combinations that make no sense
or have no effect. See scikit-learn documentation for more information,
for example: <a class="reference external" href="https://scikit-learn.org/stable/modules/grid_search.html">https://scikit-learn.org/stable/modules/grid_search.html</a></p>
<p>For DummyClassifier, parameter grid defaults to empty dictionary, class
predictions are estimated using default strategy.</p>
</dd>
<dt><strong>screening_percentile: int, float, optional, in the closed interval [0, 100]</strong></dt><dd><p>The percentage of brain volume that will be kept with respect to a full
MNI template. In particular, if it is lower than 100, a univariate
feature selection based on the Anova F-value for the input data will be
performed. A float according to a percentile of the highest
scores. Default: 20.</p>
</dd>
<dt><strong>scoring: str, callable or None, optional. Default: ‘roc_auc’</strong></dt><dd><p>The scoring strategy to use. See the scikit-learn documentation at
<a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules">https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules</a>
If callable, takes as arguments the fitted estimator, the
test data (X_test) and the test target (y_test) if y is
not None.
e.g. scorer(estimator, X_test, y_test)</p>
<p>For classification, valid entries are: ‘accuracy’, ‘f1’, ‘precision’,
‘recall’ or ‘roc_auc’. Default: ‘roc_auc’.</p>
</dd>
<dt><strong>smoothing_fwhm</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>, optional.</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">smoothing_fwhm</span></code> is not <code class="docutils literal notranslate"><span class="pre">None</span></code>, it gives
the <a class="reference internal" href="../../glossary.html#term-FWHM"><span class="xref std std-term">full-width at half maximum</span></a> in millimeters
of the spatial smoothing to apply to the signal.</p>
</dd>
<dt><strong>standardize</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#bool" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, optional.</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">standardize</span></code> is True, the data are centered and normed:
their mean is put to 0 and their variance is put to 1 in the
time dimension.
Default=True.</p>
</dd>
<dt><strong>target_affine</strong><span class="classifier"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>, optional.</span></dt><dd><p>If specified, the image is resampled corresponding to this new affine.
<code class="docutils literal notranslate"><span class="pre">target_affine</span></code> can be a 3x3 or a 4x4 matrix.
Default=None.</p>
</dd>
<dt><strong>target_shape</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> or <a class="reference external" href="https://docs.python.org/3.9/library/stdtypes.html#list" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a>, optional.</span></dt><dd><p>If specified, the image will be resized to match this new shape.
<code class="docutils literal notranslate"><span class="pre">len(target_shape)</span></code> must be equal to 3.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">target_shape</span></code> is specified, a <code class="docutils literal notranslate"><span class="pre">target_affine</span></code> of shape
<code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">4)</span></code> must also be given.</p>
</div>
<p>Default=None.</p>
</dd>
<dt><strong>low_pass</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a> or None, optional</span></dt><dd><p>Low cutoff frequency in Hertz. If specified, signals above this
frequency will be filtered out. If None, no low-pass filtering
will be performed. Default=None.</p>
</dd>
<dt><strong>high_pass</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>, optional</span></dt><dd><p>High cutoff frequency in Hertz. If specified, signals below this
frequency will be filtered out. Default=None.</p>
</dd>
<dt><strong>t_r</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a> or None, optional</span></dt><dd><p>Repetition time, in seconds (sampling period).
Set to <code class="docutils literal notranslate"><span class="pre">None</span></code> if not provided.
Default=None.</p>
</dd>
<dt><strong>mask_strategy</strong><span class="classifier">{‘background’, ‘epi’, ‘whole-brain-template’,’gm-template’, ‘wm-template’}, optional</span></dt><dd><p>The strategy used to compute the mask:</p>
<blockquote>
<div><ul>
<li><p>‘background’: Use this option if your images present
a clear homogeneous background.</p></li>
<li><p>‘epi’: Use this option if your images are raw EPI images</p></li>
<li><p>‘whole-brain-template’: This will extract the whole-brain
part of your data by resampling the MNI152 brain mask for
your data’s field of view.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>This option is equivalent to the previous ‘template’ option
which is now deprecated.</p>
</div>
</div></blockquote>
</li>
<li><p>‘gm-template’: This will extract the gray matter part of your
data by resampling the corresponding MNI152 template for your
data’s field of view.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.8.1.</span></p>
</div>
</div></blockquote>
</li>
<li><p>‘wm-template’: This will extract the white matter part of your
data by resampling the corresponding MNI152 template for your
data’s field of view.</p>
<blockquote>
<div><div class="versionadded">
<p><span class="versionmodified added">New in version 0.8.1.</span></p>
</div>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This parameter will be ignored if a mask image is provided.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on this value, the mask will be computed from
<a class="reference internal" href="nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask" title="nilearn.masking.compute_background_mask"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.masking.compute_background_mask</span></code></a>,
<a class="reference internal" href="nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.masking.compute_epi_mask</span></code></a>, or
<a class="reference internal" href="nilearn.masking.compute_brain_mask.html#nilearn.masking.compute_brain_mask" title="nilearn.masking.compute_brain_mask"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.masking.compute_brain_mask</span></code></a>.</p>
</div>
<p>Default is ‘background’.</p>
</dd>
<dt><strong>memory</strong><span class="classifier">instance of <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html#joblib.Memory" title="(in joblib v1.3.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Memory</span></code></a>, <a class="reference external" href="https://docs.python.org/3.9/library/stdtypes.html#str" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>, or <a class="reference external" href="https://docs.python.org/3.9/library/pathlib.html#pathlib.Path" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pathlib.Path</span></code></a></span></dt><dd><p>Used to cache the masking process.
By default, no caching is done. If a <a class="reference external" href="https://docs.python.org/3.9/library/stdtypes.html#str" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a> is given, it is the
path to the caching directory.</p>
</dd>
<dt><strong>memory_level</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>, optional.</span></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching. Zero means no caching.
Default=0.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>, optional.</span></dt><dd><p>The number of CPUs to use to do the computation. -1 means ‘all CPUs’.
Default=1.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.9/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>, optional</span></dt><dd><p>Verbosity level (0 means no message).
Default=0.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="nilearn.decoding.DecoderRegressor.html#nilearn.decoding.DecoderRegressor" title="nilearn.decoding.DecoderRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.decoding.DecoderRegressor</span></code></a></dt><dd><p>regression strategies for Neuro-imaging,</p>
</dd>
<dt><a class="reference internal" href="nilearn.decoding.FREMClassifier.html#nilearn.decoding.FREMClassifier" title="nilearn.decoding.FREMClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.decoding.FREMClassifier</span></code></a></dt><dd><p>State of the art classification pipeline for Neuroimaging</p>
</dd>
<dt><a class="reference internal" href="nilearn.decoding.SpaceNetClassifier.html#nilearn.decoding.SpaceNetClassifier" title="nilearn.decoding.SpaceNetClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.decoding.SpaceNetClassifier</span></code></a></dt><dd><p>Graph-Net and TV-L1 priors/penalties</p>
</dd>
</dl>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'svc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_grid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">screening_percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'roc_auc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing_fwhm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">standardize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'background'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3109b060e/nilearn/decoding/decoder.py#L866"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.decoding.Decoder.__init__" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.decision_function">
<span class="sig-name descname"><span class="pre">decision_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3109b060e/nilearn/decoding/decoder.py#L590"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.decoding.Decoder.decision_function" title="Permalink to this definition">#</a></dt>
<dd><p>Predict class labels for samples in X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X: list of Niimg-like objects</strong></dt><dd><p>See <a class="reference internal" href="../../manipulating_images/input_output.html#extracting-data"><span class="std std-ref">Input and output: neuroimaging data representation</span></a>.
Data on prediction is to be made. If this is a list,
the affine is considered the same for all.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>y_pred: ndarray, shape (n_samples,)</dt><dd><p>Predicted class label per sample.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3109b060e/nilearn/decoding/decoder.py#L358"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.decoding.Decoder.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Fit the decoder (learner).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X: list of Niimg-like objects</strong></dt><dd><p>See <a class="reference internal" href="../../manipulating_images/input_output.html#extracting-data"><span class="std std-ref">Input and output: neuroimaging data representation</span></a>.
Data on which model is to be fitted. If this is a list,
the affine is considered the same for all.</p>
</dd>
<dt><strong>y: numpy.ndarray of shape=(n_samples) or list of length n_samples</strong></dt><dd><p>The dependent variable (age, sex, IQ, yes/no, etc.).
Target variable to predict. Must have exactly as many elements as
3D images in niimg.</p>
</dd>
<dt><strong>groups: None</strong></dt><dd><p>Group labels for the samples used while splitting the dataset into
train/test set. Default None.</p>
<p>Note that this parameter must be specified in some scikit-learn
cross-validation generators to calculate the number of splits, e.g.
sklearn.model_selection.LeaveOneGroupOut or
sklearn.model_selection.LeavePGroupsOut.</p>
<p>For more details see
<a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data">https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data</a></p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>`masker_`</strong><span class="classifier">instance of NiftiMasker or MultiNiftiMasker</span></dt><dd><p>The NiftiMasker used to mask the data.</p>
</dd>
<dt><strong>`mask_img_`</strong><span class="classifier">Nifti1Image</span></dt><dd><p>Mask computed by the masker object.</p>
</dd>
<dt><strong>`classes_`</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>Classes to predict. For classification only.</p>
</dd>
<dt><strong>`screening_percentile_`</strong><span class="classifier">float</span></dt><dd><p>Screening percentile corrected according to volume of mask,
relative to the volume of standard brain.</p>
</dd>
<dt><strong>`coef_`</strong><span class="classifier">numpy.ndarray, shape=(n_classes, n_features)</span></dt><dd><p>Contains the mean of the models weight vector across
fold for each class. Returns None for Dummy estimators.</p>
</dd>
<dt><strong>`coef_img_`</strong><span class="classifier">dict of Nifti1Image</span></dt><dd><p>Dictionary containing <cite>coef_</cite> with class names as keys,
and <cite>coef_</cite> transformed in Nifti1Images as values. In the case of
a regression, it contains a single Nifti1Image at the key ‘beta’.
Ignored if Dummy estimators are provided.</p>
</dd>
<dt><strong>`intercept_`</strong><span class="classifier">ndarray, shape (nclasses,)</span></dt><dd><p>Intercept (a.k.a. bias) added to the decision function.
Ignored if Dummy estimators are provided.</p>
</dd>
<dt><strong>`cv_`</strong><span class="classifier">list of pairs of lists</span></dt><dd><p>List of the (n_folds,) folds. For the corresponding fold,
each pair is composed of two lists of indices,
one for the train samples and one for the test samples.</p>
</dd>
<dt><strong>`std_coef_`</strong><span class="classifier">numpy.ndarray, shape=(n_classes, n_features)</span></dt><dd><p>Contains the standard deviation of the models weight vector across
fold for each class. Note that folds are not independent, see
<a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data">https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data</a>
Ignored if Dummy estimators are provided.</p>
</dd>
<dt><strong>`std_coef_img_`</strong><span class="classifier">dict of Nifti1Image</span></dt><dd><p>Dictionary containing <cite>std_coef_</cite> with class names as keys,
and <cite>coef_</cite> transformed in Nifti1Image as values. In the case of
a regression, it contains a single Nifti1Image at the key ‘beta’.
Ignored if Dummy estimators are provided.</p>
</dd>
<dt><strong>`cv_params_`</strong><span class="classifier">dict of lists</span></dt><dd><p>Best point in the parameter grid for each tested fold
in the inner cross validation loop. The grid is empty
when Dummy estimators are provided.</p>
</dd>
<dt><strong>‘scorer_’</strong><span class="classifier">function</span></dt><dd><p>Scorer function used on the held out data to choose the best
parameters for the model.</p>
</dd>
<dt><strong>`cv_scores_`</strong><span class="classifier">dict, (classes, n_folds)</span></dt><dd><p>Scores (misclassification) for each parameter, and on each fold</p>
</dd>
<dt><strong>`n_outputs_`</strong><span class="classifier">int</span></dt><dd><p>Number of outputs (column-wise)</p>
</dd>
<dt><strong>`dummy_output_`: ndarray, shape=(n_classes, 2) or shape=(1, 1) for regression</strong></dt><dd><p>Contains dummy estimator attributes after class predictions using strategies
of DummyClassifier (class_prior) and DummyRegressor (constant)
from scikit-learn. This attribute is necessary for estimating class
predictions after fit. Returns None if non-dummy estimators are
provided.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decoding.Decoder.get_params" title="Permalink to this definition">#</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3109b060e/nilearn/decoding/decoder.py#L616"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.decoding.Decoder.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Predict a label for all X vectors indexed by the first axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X: {array-like, sparse matrix}, shape = (n_samples, n_features)</strong></dt><dd><p>Samples.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)</dt><dd><p>Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3109b060e/nilearn/decoding/decoder.py#L565"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.decoding.Decoder.score" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the prediction score using the scoring
metric defined by the scoring attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix}, shape = (n_samples, n_features)</span></dt><dd><p>Samples.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like</span></dt><dd><p>Target values.</p>
</dd>
<dt><strong>args</strong><span class="classifier">Optional arguments that can be passed to</span></dt><dd><p>scoring metrics. Example: sample_weight.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>Prediction score.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.decoding.Decoder.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.decoding.Decoder.set_params" title="Permalink to this definition">#</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v1.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-nilearn-decoding-decoder">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.decoding.Decoder</span></code><a class="headerlink" href="#examples-using-nilearn-decoding-decoder" title="Permalink to this heading">#</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the Haxby 2001 study on a fac..."><img alt="A introduction tutorial to fMRI decoding" src="../../_images/sphx_glr_plot_decoding_tutorial_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/00_tutorials/plot_decoding_tutorial.html#sphx-glr-auto-examples-00-tutorials-plot-decoding-tutorial-py"><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a></p>
  <div class="sphx-glr-thumbnail-title">A introduction tutorial to fMRI decoding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."><img alt="Decoding with ANOVA + SVM: face vs house in the Haxby dataset" src="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a decoding experiment. We use the data fr..."><img alt="Decoding of a dataset after GLM fit for signal extraction" src="../../_images/sphx_glr_plot_haxby_glm_decoding_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_glm_decoding.html#sphx-glr-auto-examples-02-decoding-plot-haxby-glm-decoding-py"><span class="std std-ref">Decoding of a dataset after GLM fit for signal extraction</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decoding of a dataset after GLM fit for signal extraction</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we set the number of features selected in an Anova-SVC approach to maximize the cross-vali..."><img alt="Setting a parameter by cross-validation" src="../../_images/sphx_glr_plot_haxby_grid_search_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_grid_search.html#sphx-glr-auto-examples-02-decoding-plot-haxby-grid-search-py"><span class="std std-ref">Setting a parameter by cross-validation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Setting a parameter by cross-validation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this script we reproduce the data analysis conducted by Haxby et al. in &quot;Distributed and Ove..."><img alt="ROI-based decoding analysis in Haxby et al. dataset" src="../../_images/sphx_glr_plot_haxby_full_analysis_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_full_analysis.html#sphx-glr-auto-examples-02-decoding-plot-haxby-full-analysis-py"><span class="std std-ref">ROI-based decoding analysis in Haxby et al. dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">ROI-based decoding analysis in Haxby et al. dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task."><img alt="Different classifiers in decoding the Haxby dataset" src="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py"><span class="std std-ref">Different classifiers in decoding the Haxby dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Different classifiers in decoding the Haxby dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial opens the box of decoding pipelines to bridge integrated functionalities provided..."><img alt="Advanced decoding using scikit learn" src="../../_images/sphx_glr_plot_advanced_decoding_scikit_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/07_advanced/plot_advanced_decoding_scikit.html#sphx-glr-auto-examples-07-advanced-plot-advanced-decoding-scikit-py"><span class="std std-ref">Advanced decoding using scikit learn</span></a></p>
  <div class="sphx-glr-thumbnail-title">Advanced decoding using scikit learn</div>
</div></div><div style='clear:both'></div></section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="nilearn.decoding.DecoderRegressor.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">nilearn.decoding.DecoderRegressor</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../decoding.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers 2010-2022
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">nilearn.decoding.Decoder</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-decoding-decoder">Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.decoding.Decoder</span></code></a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    </body>
</html>