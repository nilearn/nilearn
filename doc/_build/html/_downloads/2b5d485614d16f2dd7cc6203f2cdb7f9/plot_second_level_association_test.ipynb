{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example of generic design in second-level models\n\nThis example shows the results obtained in a group analysis using a more\ncomplex contrast than a one- or two-sample t test.\nWe use the [left button press (auditory cue)] task from the Localizer\ndataset and seek association between the contrast values and a variate\nthat measures the speed of pseudo-word reading. No confounding variate\nis included in the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Virgile Fritsch, Bertrand Thirion, 2014 -- 2018\n#         Jerome-Alexis Chevalier, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At first, we need to load the Localizer contrasts.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets\nn_samples = 94\nlocalizer_dataset = datasets.fetch_localizer_contrasts(\n    ['left button press (auditory cue)'],\n    n_subjects=n_samples, legacy_format=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's print basic information on the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('First contrast nifti image (3D) is located at: %s' %\n      localizer_dataset.cmaps[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we also need to load the behavioral variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tested_var = localizer_dataset.ext_vars['pseudo']\nprint(tested_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is worth to do a auality check and remove subjects with missing values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nmask_quality_check = np.where(\n    np.logical_not(np.isnan(tested_var))\n)[0]\nn_samples = mask_quality_check.size\ncontrast_map_filenames = [localizer_dataset.cmaps[i]\n                          for i in mask_quality_check]\ntested_var = tested_var[mask_quality_check].values.reshape((-1, 1))\nprint(\"Actual number of subjects after quality check: %d\" % n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate second level model\nWe define the input maps and the design matrix for the second level model\nand fit it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\ndesign_matrix = pd.DataFrame(\n    np.hstack((tested_var, np.ones_like(tested_var))),\n    columns=['fluency', 'intercept'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit of the second-level model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.second_level import SecondLevelModel\nmodel = SecondLevelModel(smoothing_fwhm=5.0)\nmodel.fit(contrast_map_filenames, design_matrix=design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the contrast is very simple. We can just provide the column\nname of the design matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_map = model.compute_contrast('fluency', output_type='z_score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the fdr-corrected p = 0.05 threshold for these data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm import threshold_stats_img\n_, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fdr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us plot the second level contrast at the computed thresholds\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\nplotting.plot_stat_map(\n    z_map, threshold=threshold, colorbar=True,\n    title='Group-level association between motor activity \\n'\n    'and reading fluency (fdr=0.05)')\n\nplotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing the (corrected) p-values with parametric test to compare with\nnon parametric test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import math_img\nfrom nilearn.image import get_data\n\np_val = model.compute_contrast('fluency', output_type='p_value')\nn_voxels = np.sum(get_data(model.masker_.mask_img_))\n# Correcting the p-values for multiple testing and taking negative logarithm\nneg_log_pval = math_img(\"-np.log10(np.minimum(1, img * {}))\"\n                        .format(str(n_voxels)),\n                        img=p_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us plot the (corrected) negative log  p-values for the parametric test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cut_coords = [38, -17, -3]\n# Since we are plotting negative log p-values and using a threshold equal to 1,\n# it corresponds to corrected p-values lower than 10%, meaning that there\n# is less than 10% probability to make a single false discovery\n# (90% chance that we make no false discoveries at all).\n# This threshold is much more conservative than the previous one.\nthreshold = 1\ntitle = ('Group-level association between motor activity and reading: \\n'\n         'neg-log of parametric corrected p-values (FWER < 10%)')\nplotting.plot_stat_map(neg_log_pval, colorbar=True, cut_coords=cut_coords,\n                       threshold=threshold, title=title)\nplotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing the (corrected) negative log p-values with permutation test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.second_level import non_parametric_inference\nneg_log_pvals_permuted_ols_unmasked = \\\n    non_parametric_inference(contrast_map_filenames,\n                             design_matrix=design_matrix,\n                             second_level_contrast='fluency',\n                             model_intercept=True, n_perm=1000,\n                             two_sided_test=False, mask=None,\n                             smoothing_fwhm=5.0, n_jobs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us plot the (corrected) negative log  p-values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "title = ('Group-level association between motor activity and reading: \\n'\n         'neg-log of non-parametric corrected p-values (FWER < 10%)')\nplotting.plot_stat_map(neg_log_pvals_permuted_ols_unmasked, colorbar=True,\n                       cut_coords=cut_coords, threshold=threshold,\n                       title=title)\nplotting.show()\n\n# The neg-log p-values obtained with non parametric testing are capped at 3\n# since the number of permutations is 1e3.\n# The non parametric test yields a few more discoveries\n# and is then more powerful than the usual parametric procedure."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}