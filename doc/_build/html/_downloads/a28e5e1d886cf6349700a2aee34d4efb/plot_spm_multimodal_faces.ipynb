{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Single-subject data (two sessions) in native space\n\nThe example shows the analysis of an SPM dataset studying face perception.  The\nanalysis is performed in native space. Realignment parameters are provided with\nthe input images, but those have not been resampled to a common space.\n\nThe experimental paradigm is simple, with two conditions; viewing a face image\nor a scrambled face image, supposedly with the same low-level statistical\nproperties, to find face-specific responses.\n\nFor details on the data, please see:\nHenson, R.N., Goshen-Gottstein, Y., Ganel, T., Otten, L.J., Quayle, A.,\nRugg, M.D. Electrophysiological and haemodynamic correlates of face\nperception, recognition and priming. Cereb Cortex. 2003 Jul;13(7):793-805.\nhttp://www.dx.doi.org/10.1093/cercor/13.7.793\n\nThis example takes a lot of time because the input are lists of 3D images\nsampled in different positions (encoded by different affine functions).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fetch the SPM multimodal_faces data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_spm_multimodal_fmri\nsubject_data = fetch_spm_multimodal_fmri()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specfiy timing and design matrix parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tr = 2.  # repetition time, in seconds\nslice_time_ref = 0.  # Sample at the beginning of each acquisition.\ndrift_model = 'Cosine'  # We use a discrete cosine transform to model signal drifts.\nhigh_pass = .01  # The cutoff for the drift model is 0.01 Hz.\nhrf_model = 'spm + derivative'  # The hemodynamic response function is the SPM canonical one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resample the images.\n\nThis is achieved by the concat_imgs function of Nilearn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nfrom nilearn.image import concat_imgs, resample_img, mean_img\n\n# Avoid getting too many warnings due to resampling\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fmri_img = [concat_imgs(subject_data.func1, auto_resample=True),\n                concat_imgs(subject_data.func2, auto_resample=True)]\naffine, shape = fmri_img[0].affine, fmri_img[0].shape\nprint('Resampling the second image (this takes time)...')\nfmri_img[1] = resample_img(fmri_img[1], affine, shape[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create mean image for display purposes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_image = mean_img(fmri_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make the design matrices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom nilearn.glm.first_level import make_first_level_design_matrix\ndesign_matrices = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loop over the two sessions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for idx, img in enumerate(fmri_img, start=1):\n    # Build experimental paradigm\n    n_scans = img.shape[-1]\n    events = pd.read_table(subject_data['events{}'.format(idx)])\n    # Define the sampling times for the design matrix\n    frame_times = np.arange(n_scans) * tr\n    # Build design matrix with the reviously defined parameters\n    design_matrix = make_first_level_design_matrix(\n            frame_times,\n            events,\n            hrf_model=hrf_model,\n            drift_model=drift_model,\n            high_pass=high_pass,\n            )\n\n    # put the design matrices in a list\n    design_matrices.append(design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can specify basic contrasts (to get :term:`beta<Parameter Estimate>`\nmaps).\nWe start by specifying canonical contrast that isolate design matrix columns.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_matrix = np.eye(design_matrix.shape[1])\nbasic_contrasts = dict([(column, contrast_matrix[i])\n                        for i, column in enumerate(design_matrix.columns)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We actually want more interesting contrasts. The simplest contrast\njust makes the difference between the two main conditions.  We\ndefine the two opposite versions to run one-tailed t-tests.  We also\ndefine the effects of interest contrast, a 2-dimensional contrasts\nspanning the two conditions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrasts = {\n    'faces-scrambled': basic_contrasts['faces'] - basic_contrasts['scrambled'],\n    'scrambled-faces': -basic_contrasts['faces'] + basic_contrasts['scrambled'],\n    'effects_of_interest': np.vstack((basic_contrasts['faces'],\n                                      basic_contrasts['scrambled']))\n    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the GLM for the 2 sessions by specifying a FirstLevelModel and then\nfitting it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import FirstLevelModel\nprint('Fitting a GLM')\nfmri_glm = FirstLevelModel()\nfmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compute contrast-related statistical maps (in z-scale), and plot\nthem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Computing contrasts')\nfrom nilearn import plotting\n\n# Iterate on contrasts\nfor contrast_id, contrast_val in contrasts.items():\n    print(\"\\tcontrast id: %s\" % contrast_id)\n    # compute the contrasts\n    z_map = fmri_glm.compute_contrast(\n        contrast_val, output_type='z_score')\n    # plot the contrasts as soon as they're generated\n    # the display is overlaid on the mean fMRI image\n    # a threshold of 3.0 is used, more sophisticated choices are possible\n    plotting.plot_stat_map(\n        z_map, bg_img=mean_image, threshold=3.0, display_mode='z',\n        cut_coords=3, black_bg=True, title=contrast_id)\n    plotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the resulting maps we observe that the analysis results in\nwide activity for the 'effects of interest' contrast, showing the\nimplications of large portions of the visual cortex in the\nconditions. By contrast, the differential effect between \"faces\" and\n\"scrambled\" involves sparser, more anterior and lateral regions. It\nalso displays some responses in the frontal lobe.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}