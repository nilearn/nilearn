{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# NeuroVault cross-study ICA maps.\n\nThis example shows how to download statistical maps from\nNeuroVault, label them with NeuroSynth terms,\nand compute :term:`ICA` components across all the maps.\n\nSee :func:`nilearn.datasets.fetch_neurovault`\ndocumentation for more details.\n\n.. include:: ../../../examples/masker_note.rst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Ben Cipollini\n# License: BSD\n# Ported from code authored by Chris Filo Gorgolewski, Gael Varoquaux\n# https://github.com/NeuroVault/neurovault_analysis\nimport warnings\n\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.decomposition import FastICA\n\nfrom nilearn.datasets import fetch_neurovault\nfrom nilearn.image import smooth_img\n\nfrom nilearn.datasets import load_mni152_brain_mask\nfrom nilearn.maskers import NiftiMasker\n\nfrom nilearn import plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get image and term data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Download images\n# Here by default we only download 80 images to save time,\n# but for better results I recommend using at least 200.\nprint(\"Fetching Neurovault images; \"\n      \"if you haven't downloaded any Neurovault data before \"\n      \"this will take several minutes.\")\nnv_data = fetch_neurovault(max_images=30, fetch_neurosynth_words=True)\n\nimages = nv_data['images']\nterm_weights = nv_data['word_frequencies']\nvocabulary = nv_data['vocabulary']\nif term_weights is None:\n    term_weights = np.ones((len(images), 2))\n    vocabulary = np.asarray(\n        [\"Neurosynth is down\", \"Please try again later\"])\n\n# Clean and report term scores\nterm_weights[term_weights < 0] = 0\ntotal_scores = np.mean(term_weights, axis=0)\n\nprint(\"\\nTop 10 neurosynth terms from downloaded images:\\n\")\n\nfor term_idx in np.argsort(total_scores)[-10:][::-1]:\n    print(vocabulary[term_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reshape and mask images\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nReshaping and masking images.\\n\")\n\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore', UserWarning)\n    warnings.simplefilter('ignore', DeprecationWarning)\n\n    mask_img = load_mni152_brain_mask(resolution=2)\n    masker = NiftiMasker(\n        mask_img=mask_img, memory='nilearn_cache', memory_level=1)\n    masker = masker.fit()\n\n    # Images may fail to be transformed, and are of different shapes,\n    # so we need to transform one-by-one and keep track of failures.\n    X = []\n    is_usable = np.ones((len(images),), dtype=bool)\n\n    for index, image_path in enumerate(images):\n        # load image and remove nan and inf values.\n        # applying smooth_img to an image with fwhm=None simply cleans up\n        # non-finite values but otherwise doesn't modify the image.\n        image = smooth_img(image_path, fwhm=None)\n        try:\n            X.append(masker.transform(image))\n        except Exception as e:\n            meta = nv_data['images_meta'][index]\n            print(\"Failed to mask/reshape image: id: {0}; \"\n                  \"name: '{1}'; collection: {2}; error: {3}\".format(\n                      meta.get('id'), meta.get('name'),\n                      meta.get('collection_id'), e))\n            is_usable[index] = False\n\n# Now reshape list into 2D matrix, and remove failed images from terms\nX = np.vstack(X)\nterm_weights = term_weights[is_usable, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run ICA and map components to terms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Running ICA; may take time...\")\n# We use a very small number of components as we have downloaded only 80\n# images. For better results, increase the number of images downloaded\n# and the number of components\nn_components = 8\nfast_ica = FastICA(n_components=n_components, random_state=0)\nica_maps = fast_ica.fit_transform(X.T).T\n\nterm_weights_for_components = np.dot(fast_ica.components_, term_weights)\nprint('Done, plotting results.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate figures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with warnings.catch_warnings():\n    warnings.simplefilter('ignore', DeprecationWarning)\n\n    for index, (ic_map, ic_terms) in enumerate(\n            zip(ica_maps, term_weights_for_components)):\n        if -ic_map.min() > ic_map.max():\n            # Flip the map's sign for prettiness\n            ic_map = - ic_map\n            ic_terms = - ic_terms\n\n        ic_threshold = stats.scoreatpercentile(np.abs(ic_map), 90)\n        ic_img = masker.inverse_transform(ic_map)\n        important_terms = vocabulary[np.argsort(ic_terms)[-3:]]\n        title = 'IC%i  %s' % (index, ', '.join(important_terms[::-1]))\n\n        plotting.plot_stat_map(\n            ic_img, threshold=ic_threshold, colorbar=False,\n            title=title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, some of the components capture cognitive or neurological\nmaps, while other capture noise in the database. More data, better\nfiltering, and better cognitive labels would give better maps\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Done.\nplotting.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}