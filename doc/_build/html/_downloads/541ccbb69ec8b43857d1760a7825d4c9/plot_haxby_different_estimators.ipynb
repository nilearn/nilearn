{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Different classifiers in decoding the Haxby dataset\n\nHere we compare different classifiers on a visual object recognition\ndecoding task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We start by loading data using nilearn dataset fetcher\nfrom nilearn import datasets\nfrom nilearn.image import get_data\n# by default 2nd subject data will be fetched\nhaxby_dataset = datasets.fetch_haxby()\n\n# print basic information on the dataset\nprint('First subject anatomical nifti image (3D) located is at: %s' %\n      haxby_dataset.anat[0])\nprint('First subject functional nifti image (4D) is located at: %s' %\n      haxby_dataset.func[0])\n\n# load labels\nimport numpy as np\nimport pandas as pd\nlabels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\nstimuli = labels['labels']\n\n# identify resting state (baseline) labels in order to be able to remove them\nresting_state = (stimuli == 'rest')\n\n# extract the indices of the images corresponding to some condition or task\ntask_mask = np.logical_not(resting_state)\n\n# find names of remaining active labels\ncategories = stimuli[task_mask].unique()\n\n# extract tags indicating to which acquisition run a tag belongs\nsession_labels = labels['chunks'][task_mask]\n\n\n# Load the fMRI data\n# For decoding, standardizing is often very important\nmask_filename = haxby_dataset.mask_vt[0]\nfunc_filename = haxby_dataset.func[0]\n\n\n# Because the data is in one single large 4D image, we need to use\n# index_img to do the split easily.\nfrom nilearn.image import index_img\nfmri_niimgs = index_img(func_filename, task_mask)\nclassification_target = stimuli[task_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the decoder\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Then we define the various classifiers that we use\nclassifiers = ['svc_l2', 'svc_l1', 'logistic_l1',\n               'logistic_l2', 'ridge_classifier']\n\n# Here we compute prediction scores and run time for all these\n# classifiers\nimport time\nfrom nilearn.decoding import Decoder\nfrom sklearn.model_selection import LeaveOneGroupOut\n\ncv = LeaveOneGroupOut()\nclassifiers_data = {}\n\nfor classifier_name in sorted(classifiers):\n    print(70 * '_')\n\n    # The decoder has as default score the `roc_auc`\n    decoder = Decoder(estimator=classifier_name, mask=mask_filename,\n                      standardize=True, cv=cv)\n    t0 = time.time()\n    decoder.fit(fmri_niimgs, classification_target, groups=session_labels)\n\n    classifiers_data[classifier_name] = {}\n    classifiers_data[classifier_name]['score'] = decoder.cv_scores_\n\n    print(\"%10s: %.2fs\" % (classifier_name, time.time() - t0))\n    for category in categories:\n        print(\"    %14s vs all -- AUC: %1.2f +- %1.2f\" % (\n            category,\n            np.mean(classifiers_data[classifier_name]['score'][category]),\n            np.std(classifiers_data[classifier_name]['score'][category]))\n        )\n\n    # Adding the average performance per estimator\n    scores = classifiers_data[classifier_name]['score']\n    scores['AVERAGE'] = np.mean(list(scores.values()), axis=0)\n    classifiers_data[classifier_name]['score'] = scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Then we make a rudimentary diagram\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6, 6))\n\nall_categories = np.sort(np.hstack([categories, 'AVERAGE']))\ntick_position = np.arange(len(all_categories))\nplt.yticks(tick_position + 0.25, all_categories)\nheight = 0.1\n\nfor i, (color, classifier_name) in enumerate(zip(['b', 'm', 'k', 'r', 'g'],\n                                                 classifiers)):\n    score_means = [\n        np.mean(classifiers_data[classifier_name]['score'][category])\n        for category in all_categories\n    ]\n\n    plt.barh(tick_position, score_means,\n             label=classifier_name.replace('_', ' '),\n             height=height, color=color)\n    tick_position = tick_position + height\n\nplt.xlabel('Classification accuracy (AUC score)')\nplt.ylabel('Visual stimuli category')\nplt.xlim(xmin=0.5)\nplt.legend(loc='lower left', ncol=1)\nplt.title(\n    'Category-specific classification accuracy for different classifiers')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that for a fixed penalty the results are similar between the svc\nand the logistic regression. The main difference relies on the penalty\n($\\ell_1$ and $\\ell_2$). The sparse penalty works better because we are in\nan intra-subject setting.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the face vs house map\n\nRestrict the decoding to face vs house\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "condition_mask = np.logical_or(stimuli == 'face', stimuli == 'house')\nstimuli = stimuli[condition_mask]\nassert len(stimuli) == 216\nfmri_niimgs_condition = index_img(func_filename, condition_mask)\nsession_labels = labels['chunks'][condition_mask]\ncategories = stimuli.unique()\nassert len(categories) == 2\n\nfor classifier_name in sorted(classifiers):\n    decoder = Decoder(estimator=classifier_name, mask=mask_filename,\n                      standardize=True, cv=cv)\n    decoder.fit(fmri_niimgs_condition, stimuli, groups=session_labels)\n    classifiers_data[classifier_name] = {}\n    classifiers_data[classifier_name]['score'] = decoder.cv_scores_\n    classifiers_data[classifier_name]['map'] = decoder.coef_img_['face']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the face vs house map for the different classifiers\nUse the average EPI as a background\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import mean_img\nfrom nilearn.plotting import plot_stat_map, show\nmean_epi_img = mean_img(func_filename)\n\nfor classifier_name in sorted(classifiers):\n    coef_img = classifiers_data[classifier_name]['map']\n    threshold = np.max(np.abs(get_data(coef_img))) * 1e-3\n    plot_stat_map(\n        coef_img, bg_img=mean_epi_img, display_mode='z', cut_coords=[-15],\n        threshold=threshold,\n        title='%s: face vs house' % classifier_name.replace('_', ' '))\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}