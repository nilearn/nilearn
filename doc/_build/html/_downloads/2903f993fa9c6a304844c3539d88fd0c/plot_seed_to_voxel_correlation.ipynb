{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Producing single subject maps of seed-to-voxel correlation\n\nThis example shows how to produce seed-to-:term:`voxel` correlation maps\nfor a single subject based on movie-watching :term:`fMRI` scans.\nThese maps depict the temporal correlation of a **seed region** with the\n**rest of the brain**.\n\nThis example is an advanced one that requires manipulating the data with numpy.\nNote the difference between images, that lie in brain space, and the\nnumpy array, corresponding to the data inside the mask.\n\nSee also `for a similar example using cortical surface input data\n<sphx_glr_auto_examples_01_plotting_plot_surf_stat_map.py>`.\n\nAuthor: Franz Liem\n\n.. include:: ../../../examples/masker_note.rst\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting the data\n\nWe will work with the first subject of the brain development fmri data set.\ndataset.func is a list of filenames. We select the 1st (0-based)\nsubject by indexing with [0]).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets\n\ndataset = datasets.fetch_development_fmri(n_subjects=1)\nfunc_filename = dataset.func[0]\nconfound_filename = dataset.confounds[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that func_filename and confound_filename are strings pointing to\nfiles on your hard drive.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(func_filename)\nprint(confound_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time series extraction\n\nWe are going to extract signals from the functional time series in two\nsteps. First we will extract the mean signal within the **seed region of\ninterest**. Second, we will extract the **brain-wide voxel-wise time series**.\n\nWe will be working with one seed sphere in the Posterior Cingulate Cortex\n(PCC), considered part of the Default Mode Network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pcc_coords = [(0, -52, 18)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use :class:`nilearn.maskers.NiftiSpheresMasker` to extract the\n**time series from the functional imaging within the sphere**. The\nsphere is centered at pcc_coords and will have the radius we pass the\nNiftiSpheresMasker function (here 8 mm).\n\nThe extraction will also detrend, standardize, and bandpass filter the data.\nThis will create a NiftiSpheresMasker object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.maskers import NiftiSpheresMasker\n\nseed_masker = NiftiSpheresMasker(\n    pcc_coords, radius=8, detrend=True, standardize=True,\n    low_pass=0.1, high_pass=0.01, t_r=2,\n    memory='nilearn_cache', memory_level=1, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we extract the mean time series within the seed region while\nregressing out the confounds that\ncan be found in the dataset's csv file\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed_time_series = seed_masker.fit_transform(func_filename,\n                                             confounds=[confound_filename])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we can proceed similarly for the **brain-wide voxel-wise time\nseries**, using :class:`nilearn.maskers.NiftiMasker` with the same input\narguments as in the seed_masker in addition to smoothing with a 6 mm kernel\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.maskers import NiftiMasker\n\nbrain_masker = NiftiMasker(\n    smoothing_fwhm=6, detrend=True, standardize=True,\n    low_pass=0.1, high_pass=0.01, t_r=2,\n    memory='nilearn_cache', memory_level=1, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we extract the brain-wide voxel-wise time series while regressing\nout the confounds as before\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain_time_series = brain_masker.fit_transform(func_filename,\n                                               confounds=[confound_filename])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now inspect the extracted time series. Note that the **seed time\nseries** is an array with shape n_volumes, 1), while the\n**brain time series** is an array with shape (n_volumes, n_voxels).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Seed time series shape: (%s, %s)\" % seed_time_series.shape)\nprint(\"Brain time series shape: (%s, %s)\" % brain_time_series.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the **seed time series**.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.plot(seed_time_series)\nplt.title('Seed time series (Posterior cingulate cortex)')\nplt.xlabel('Scan number')\nplt.ylabel('Normalized signal')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exemplarily, we can also select 5 random voxels from the **brain-wide\ndata** and plot the time series from.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(brain_time_series[:, [10, 45, 100, 5000, 10000]])\nplt.title('Time series from 5 random voxels')\nplt.xlabel('Scan number')\nplt.ylabel('Normalized signal')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performing the seed-to-voxel correlation analysis\n\nNow that we have two arrays (**sphere signal**: (n_volumes, 1),\n**brain-wide voxel-wise signal** (n_volumes, n_voxels)), we can correlate\nthe **seed signal** with the **signal of each voxel**. The dot product of\nthe two arrays will give us this correlation. Note that the signals have\nbeen variance-standardized during extraction. To have them standardized to\nnorm unit, we further have to divide the result by the length of the time\nseries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nseed_to_voxel_correlations = (np.dot(brain_time_series.T, seed_time_series) /\n                              seed_time_series.shape[0]\n                              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The resulting array will contain a value representing the correlation\nvalues between the signal in the **seed region** of interest and **each\nvoxel's signal**, and will be of shape (n_voxels, 1). The correlation\nvalues can potentially range between -1 and 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Seed-to-voxel correlation shape: (%s, %s)\" %\n      seed_to_voxel_correlations.shape)\nprint(\"Seed-to-voxel correlation: min = %.3f; max = %.3f\" % (\n    seed_to_voxel_correlations.min(), seed_to_voxel_correlations.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the seed-to-voxel correlation map\nWe can now plot the seed-to-voxel correlation map and perform thresholding\nto only show values more extreme than +/- 0.5. Before displaying,\nwe need to create an in memory Nifti image object.\nFurthermore, we can display the location of the seed with a sphere and\nset the cross to the center of the seed region of interest.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\n\nseed_to_voxel_correlations_img = brain_masker.inverse_transform(\n    seed_to_voxel_correlations.T)\ndisplay = plotting.plot_stat_map(seed_to_voxel_correlations_img,\n                                 threshold=0.5, vmax=1,\n                                 cut_coords=pcc_coords[0],\n                                 title=\"Seed-to-voxel correlation (PCC seed)\"\n                                 )\ndisplay.add_markers(marker_coords=pcc_coords, marker_color='g',\n                    marker_size=300)\n# At last, we save the plot as pdf.\ndisplay.savefig('pcc_seed_correlation.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fisher-z transformation and save nifti\nFinally, we can Fisher-z transform the data to achieve a normal distribution.\nThe transformed array can now have values more extreme than +/- 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed_to_voxel_correlations_fisher_z = np.arctanh(seed_to_voxel_correlations)\nprint(\"Seed-to-voxel correlation Fisher-z transformed: min = %.3f; max = %.3f\"\n      % (seed_to_voxel_correlations_fisher_z.min(),\n         seed_to_voxel_correlations_fisher_z.max()\n         )\n      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eventually, we can transform the correlation array back to a Nifti image\nobject, that we can save.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed_to_voxel_correlations_fisher_z_img = brain_masker.inverse_transform(\n    seed_to_voxel_correlations_fisher_z.T)\nseed_to_voxel_correlations_fisher_z_img.to_filename(\n    'pcc_seed_correlation_z.nii.gz')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}