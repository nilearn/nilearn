{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# FREM on Jimura et al \"mixed gambles\" dataset.\n\nIn this example, we use fast ensembling of regularized models (FREM) to\nsolve a regression problem, predicting the gain level corresponding to each\nbeta maps regressed from mixed gambles experiment. FREM uses an implicit\nspatial regularization through fast clustering and aggregates a high number\nof  estimators trained on various splits of the training set, thus returning\na very robust decoder at a lower computational cost than other spatially\nregularized methods.\n\nTo have more details, see: `frem`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data from the Jimura mixed-gamble experiment\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_mixed_gambles\ndata = fetch_mixed_gambles(n_subjects=16)\n\nzmap_filenames = data.zmaps\nbehavioral_target = data.gain\nmask_filename = data.mask_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit FREM\nWe compare both of these models to a pipeline ensembling many models\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.decoding import FREMRegressor\nfrem = FREMRegressor('svr', cv=10)\n\nfrem.fit(zmap_filenames, behavioral_target)\n\n# Visualize FREM weights\n# ---------------------------------------------------------------------------\n\nfrom nilearn.plotting import plot_stat_map\nplot_stat_map(frem.coef_img_['beta'], title=\"FREM\", display_mode=\"yz\",\n              cut_coords=[20, -2], threshold=.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can observe that the coefficients map learnt by FREM is structured,\ndue to the spatial regularity imposed by working on clusters and model\nensembling. Although these maps have been thresholded for display, they are\nnot sparse (i.e. almost all\u00a0voxels have non-zero coefficients). See also this\n`other example <sphx_glr_auto_examples_02_decoding_plot_haxby_frem.py>`\nusing FREM, and related `section of user guide <frem>`.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example use of TV-L1 SpaceNet\n`SpaceNet<space_net>` is another method available in Nilearn to decode\nwith spatially sparse models. Depending on the penalty that is used,\nit yields either very structured maps (TV-L1) or unstructured maps\n(graph_net). Because of their heavy computational costs, these methods are\nnot demonstrated on this example but you can try them easily if you have a\nfew minutes. Example code is included below.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.decoding import SpaceNetRegressor\n\n# We use the regressor object since the task is to predict a continuous\n# variable (gain of the gamble).\n\ntv_l1 = SpaceNetRegressor(mask=mask_filename, penalty=\"tv-l1\",\n                          eps=1e-1,  # prefer large alphas\n                          memory=\"nilearn_cache\")\n# tv_l1.fit(zmap_filenames, behavioral_target)\n# plot_stat_map(tv_l1.coef_img_, title=\"TV-L1\", display_mode=\"yz\",\n#               cut_coords=[20, -2])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}