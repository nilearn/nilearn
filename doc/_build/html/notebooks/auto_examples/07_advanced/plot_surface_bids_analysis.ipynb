{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Surface-based dataset first and second level analysis of a dataset\n\n\nFull step-by-step example of fitting a :term:`GLM` (first and second level\nanalysis) in a 10-subjects dataset and visualizing the results.\n\nMore specifically:\n\n1. Download an :term:`fMRI` :term:`BIDS` dataset with two language conditions to contrast.\n2. Project the data to a standard mesh, fsaverage5, aka the Freesurfer template mesh downsampled to about 10k nodes per hemisphere.\n3. Run the first level model objects.\n4. Fit a second level model on the fitted first level models.\n\nNotice that in this case the preprocessed :term:`bold<BOLD>` images were already normalized to the same :term:`MNI` space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch example BIDS dataset\nWe download a simplified :term:`BIDS` dataset made available for illustrative\npurposes. It contains only the necessary\ninformation to run a statistical analysis using Nilearn. The raw data\nsubject folders only contain bold.json and events.tsv files, while the\nderivatives folder includes the preprocessed files preproc.nii and the\nconfounds.tsv files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_language_localizer_demo_dataset\ndata_dir, _ = fetch_language_localizer_demo_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the location of the dataset on disk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain automatically FirstLevelModel objects and fit arguments\nFrom the dataset directory we automatically obtain the FirstLevelModel objects\nwith their subject_id filled from the :term:`BIDS` dataset. Moreover, we obtain\nfor each model a dictionary with run_imgs, events and confounder regressors\nsince in this case a confounds.tsv file is available in the :term:`BIDS` dataset.\nTo get the first level models we only have to specify the dataset directory\nand the task_label as specified in the file names.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import first_level_from_bids\ntask_label = 'languagelocalizer'\n_, models_run_imgs, models_events, models_confounds = \\\n    first_level_from_bids(\n        data_dir, task_label,\n        img_filters=[('desc', 'preproc')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also need to get the TR information. For that we use the json sidecar file\nof the dataset's functional images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\njson_file = os.path.join(data_dir, 'derivatives', 'sub-01', 'func',\n                         'sub-01_task-languagelocalizer_desc-preproc_bold.json')\nimport json\nwith open(json_file, 'r') as f:\n    t_r = json.load(f)['RepetitionTime']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Project fMRI data to the surface: First get fsaverage5.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_surf_fsaverage\nfsaverage = fetch_surf_fsaverage(mesh='fsaverage5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The projection function simply takes the fMRI data and the mesh.\nNote that those correspond spatially, as they are both in MNI space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom nilearn import surface\nfrom nilearn.glm.first_level import make_first_level_design_matrix\nfrom nilearn.glm.first_level import run_glm\nfrom nilearn.glm.contrasts import compute_contrast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Empty lists in which we are going to store activation values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_scores_right = []\nz_scores_left = []\nfor (fmri_img, confound, events) in zip(\n        models_run_imgs, models_confounds, models_events):\n    texture = surface.vol_to_surf(fmri_img[0], fsaverage.pial_right)\n    n_scans = texture.shape[1]\n    frame_times = t_r * (np.arange(n_scans) + .5)\n\n    # Create the design matrix\n    #\n    # We specify an hrf model containing Glover model and its time derivative.\n    # The drift model is implicitly a cosine basis with period cutoff 128s.\n    design_matrix = make_first_level_design_matrix(\n        frame_times, events=events[0], hrf_model='glover + derivative',\n        add_regs=confound[0])\n\n    # Contrast specification\n    contrast_values = (design_matrix.columns == 'language') * 1.0 -\\\n                      (design_matrix.columns == 'string')\n\n    # Setup and fit GLM.\n    # Note that the output consists in 2 variables: `labels` and `fit`\n    # `labels` tags voxels according to noise autocorrelation.\n    # `estimates` contains the parameter estimates.\n    # We input them for contrast computation.\n    labels, estimates = run_glm(texture.T, design_matrix.values)\n    contrast = compute_contrast(labels, estimates, contrast_values,\n                                contrast_type='t')\n    # We present the Z-transform of the t map.\n    z_score = contrast.z_score()\n    z_scores_right.append(z_score)\n\n    # Do the left hemisphere exactly the same way.\n    texture = surface.vol_to_surf(fmri_img, fsaverage.pial_left)\n    labels, estimates = run_glm(texture.T, design_matrix.values)\n    contrast = compute_contrast(labels, estimates, contrast_values,\n                                contrast_type='t')\n    z_scores_left.append(contrast.z_score())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Individual activation maps have been accumulated in the z_score_left\nand az_scores_right lists respectively. We can now use them in a\ngroup study (one-sample study).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group study\n\nPrepare figure for concurrent plot of individual maps\ncompute population-level maps for left and right hemisphere\nWe directly do that on the value arrays.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_1samp, norm\nt_left, pval_left = ttest_1samp(np.array(z_scores_left), 0)\nt_right, pval_right = ttest_1samp(np.array(z_scores_right), 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What we have so far are p-values: we convert them to z-values for plotting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_val_left = norm.isf(pval_left)\nz_val_right = norm.isf(pval_right)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the resulting maps, at first on the left hemisphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\nplotting.plot_surf_stat_map(\n    fsaverage.infl_left, z_val_left, hemi='left',\n    title=\"language-string, left hemisphere\", colorbar=True,\n    threshold=3., bg_map=fsaverage.sulc_left)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, on the right hemisphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotting.plot_surf_stat_map(\n    fsaverage.infl_right, z_val_left, hemi='right',\n    title=\"language-string, right hemisphere\", colorbar=True,\n    threshold=3., bg_map=fsaverage.sulc_right)\n\nplotting.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}