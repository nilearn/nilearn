{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Reconstruction of visual stimuli from Miyawaki et al. 2008\n\nThis example reproduces the experiment presented in\n    [Visual image reconstruction from human brain activity\n    using a combination of multiscale local image decoders](http://www.cell.com/neuron/abstract/S0896-6273%2808%2900958-6),\n    Miyawaki, Y., Uchida, H., Yamashita, O., Sato, M. A.,\n    Morito, Y., Tanabe, H. C., ... & Kamitani, Y. (2008).\n    Neuron, 60(5), 915-929.\n\nIt reconstructs 10x10 binary images from functional MRI data. Random images\nare used as training set and structured images are used for reconstruction.\n\nThe code is a bit elaborate as the example uses, as the original article,\na multiscale prediction on the images seen by the subject.\n\nSee also\n`sphx_glr_auto_examples_02_decoding_plot_miyawaki_encoding.py` for a\nencoding approach for the same dataset.\n\n.. include:: ../../../examples/masker_note.rst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some basic imports\nimport time\nimport sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First we load the Miyawaki dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets\nsys.stderr.write(\"Fetching dataset...\")\nt0 = time.time()\n\nmiyawaki_dataset = datasets.fetch_miyawaki2008()\n\n# print basic information on the dataset\nprint('First functional nifti image (4D) is located at: %s' %\n      miyawaki_dataset.func[0])  # 4D data\n\nX_random_filenames = miyawaki_dataset.func[12:]\nX_figure_filenames = miyawaki_dataset.func[:12]\ny_random_filenames = miyawaki_dataset.label[12:]\ny_figure_filenames = miyawaki_dataset.label[:12]\ny_shape = (10, 10)\n\nsys.stderr.write(\" Done (%.2fs).\\n\" % (time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Then we prepare and mask the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom nilearn.maskers import MultiNiftiMasker\n\nsys.stderr.write(\"Preprocessing data...\")\nt0 = time.time()\n\n# Load and mask fMRI data\nmasker = MultiNiftiMasker(mask_img=miyawaki_dataset.mask, detrend=True,\n                          standardize=False)\nmasker.fit()\nX_train = masker.transform(X_random_filenames)\nX_test = masker.transform(X_figure_filenames)\n\n# We load the visual stimuli from csv files\ny_train = []\nfor y in y_random_filenames:\n    y_train.append(np.reshape(np.loadtxt(y, dtype=int, delimiter=','),\n                              (-1,) + y_shape, order='F'))\n\ny_test = []\nfor y in y_figure_filenames:\n    y_test.append(np.reshape(np.loadtxt(y, dtype=int, delimiter=','),\n                             (-1,) + y_shape, order='F'))\n\nX_train = np.vstack([x[2:] for x in X_train])\ny_train = np.vstack([y[:-2] for y in y_train]).astype(float)\nX_test = np.vstack([x[2:] for x in X_test])\ny_test = np.vstack([y[:-2] for y in y_test]).astype(float)\n\nn_pixels = y_train.shape[1]\nn_features = X_train.shape[1]\n\n\ndef flatten(list_of_2d_array):\n    flattened = []\n    for array in list_of_2d_array:\n        flattened.append(array.ravel())\n    return flattened\n\n\n# Build the design matrix for multiscale computation\n# Matrix is squared, y_rows == y_cols\ny_cols = y_shape[1]\n\n# Original data\ndesign_matrix = np.eye(100)\n\n\n# Example of matrix used for multiscale (sum pixels vertically)\n#\n# 0.5 *\n#\n# 1 1 0 0 0 0 0 0 0 0\n# 0 1 1 0 0 0 0 0 0 0\n# 0 0 1 1 0 0 0 0 0 0\n# 0 0 0 1 1 0 0 0 0 0\n# 0 0 0 0 1 1 0 0 0 0\n# 0 0 0 0 0 1 1 0 0 0\n# 0 0 0 0 0 0 1 1 0 0\n# 0 0 0 0 0 0 0 1 1 0\n# 0 0 0 0 0 0 0 0 1 1\n\nheight_tf = (np.eye(y_cols) + np.eye(y_cols, k=1))[:y_cols - 1] * .5\nwidth_tf = height_tf.T\n\nyt_tall = [np.dot(height_tf, m) for m in y_train]\nyt_large = [np.dot(m, width_tf) for m in y_train]\nyt_big = [np.dot(height_tf, np.dot(m, width_tf)) for m in y_train]\n\n# Add it to the training set\ny_train = [np.r_[y.ravel(), t.ravel(), l.ravel(), b.ravel()]\n           for y, t, l, b in zip(y_train, yt_tall, yt_large, yt_big)]\n\ny_test = np.asarray(flatten(y_test))\ny_train = np.asarray(y_train)\n\n# Remove rest period\nX_train = X_train[y_train[:, 0] != -1]\ny_train = y_train[y_train[:, 0] != -1]\nX_test = X_test[y_test[:, 0] != -1]\ny_test = y_test[y_test[:, 0] != -1]\n\nsys.stderr.write(\" Done (%.2fs).\\n\" % (time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We define our prediction function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sys.stderr.write(\"Training classifiers... \\r\")\nt0 = time.time()\n\n# OMP: Orthogonal Matching Pursuit\nfrom sklearn.linear_model import OrthogonalMatchingPursuit as OMP\nfrom sklearn.feature_selection import f_classif, SelectKBest\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Create as many OMP as voxels to predict\nclfs = []\nn_clfs = y_train.shape[1]\nfor i in range(y_train.shape[1]):\n    sys.stderr.write(\"Training classifiers %03d/%d... \\r\" % (i + 1, n_clfs))\n\n    clf = Pipeline([('selection', SelectKBest(f_classif, k=500)),\n                    ('scl', StandardScaler()),\n                    ('clf', OMP(normalize=False, n_nonzero_coefs=10))])\n    clf.fit(X_train, y_train[:, i])\n    clfs.append(clf)\n\nsys.stderr.write(\"Training classifiers %03d/%d... Done (%.2fs).\\n\" % (\n    n_clfs, n_clfs, time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here we run the prediction: the decoding itself\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sys.stderr.write(\"Calculating scores and outputs...\")\nt0 = time.time()\n\ny_pred = []\nfor clf in clfs:\n    y_pred.append(clf.predict(X_test))\ny_pred = np.asarray(y_pred).T\n\n\n# We need to the multi scale reconstruction\ndef split_multi_scale(y, y_shape):\n    \"\"\" Split data into 4 original multi_scale images\n    \"\"\"\n    yw, yh = y_shape\n\n    # Index of original image\n    split_index = [yw * yh]\n    # Index of large image\n    split_index.append(split_index[-1] + (yw - 1) * yh)\n    # Index of tall image\n    split_index.append(split_index[-1] + yw * (yh - 1))\n    # Index of big image\n    split_index.append(split_index[-1] + (yw - 1) * (yh - 1))\n\n    # We split according to computed indices\n    y_preds = np.split(y, split_index, axis=1)\n\n    # y_pred is the original image\n    y_pred = y_preds[0]\n\n    # y_pred_tall is the image with 1x2 patch application. We have to make\n    # some calculus to get it back in original shape\n    height_tf_i = (np.eye(y_cols) + np.eye(y_cols, k=-1))[:, :y_cols - 1] * .5\n    height_tf_i.flat[0] = 1\n    height_tf_i.flat[-1] = 1\n    y_pred_tall = [np.dot(height_tf_i, np.reshape(m, (yw - 1, yh))).flatten()\n                   for m in y_preds[1]]\n    y_pred_tall = np.asarray(y_pred_tall)\n\n    # y_pred_large is the image with 2x1 patch application. We have to make\n    # some calculus to get it back in original shape\n    width_tf_i = (np.eye(y_cols) + np.eye(y_cols, k=1))[:y_cols - 1] * .5\n    width_tf_i.flat[0] = 1\n    width_tf_i.flat[-1] = 1\n    y_pred_large = [np.dot(np.reshape(m, (yw, yh - 1)), width_tf_i).flatten()\n                    for m in y_preds[2]]\n    y_pred_large = np.asarray(y_pred_large)\n\n    # y_pred_big is the image with 2x2 patch application. We use previous\n    # matrices to get it back in original shape\n    y_pred_big = [np.dot(np.reshape(m, (yw - 1, yh - 1)), width_tf_i)\n                  for m in y_preds[3]]\n    y_pred_big = [np.dot(height_tf_i, np.reshape(m, (yw - 1, yh))).flatten()\n                  for m in y_pred_big]\n    y_pred_big = np.asarray(y_pred_big)\n\n    return (y_pred, y_pred_tall, y_pred_large, y_pred_big)\n\n\ny_pred, y_pred_tall, y_pred_large, y_pred_big = \\\n    split_multi_scale(y_pred, y_shape)\n\ny_pred = (.25 * y_pred + .25 * y_pred_tall + .25 * y_pred_large\n          + .25 * y_pred_big)\n\nsys.stderr.write(\" Done (%.2fs).\\n\" % (time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let us quantify our prediction error\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n                             f1_score)\n\nprint(\"Scores\")\nprint(\"------\")\nprint(\"  - Accuracy (percent): %f\" % np.mean([\n    accuracy_score(y_test[:, i], y_pred[:, i] > .5) for i in range(100)]))\nprint(\"  - Precision: %f\" % np.mean([\n    precision_score(y_test[:, i], y_pred[:, i] > .5) for i in range(100)]))\nprint(\"  - Recall: %f\" % np.mean([\n    recall_score(y_test[:, i], y_pred[:, i] > .5, zero_division=0)\n    for i in range(100)]))\nprint(\"  - F1-score: %f\" % np.mean([\n    f1_score(y_test[:, i], y_pred[:, i] > .5) for i in range(100)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally, we plot six reconstructed images, to compare with\nground truth\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nfrom nilearn.plotting import show\n\nfor i in range(6):\n    j = 10 * i\n    fig = plt.figure()\n    sp1 = plt.subplot(131)\n    sp1.axis('off')\n    plt.title('Stimulus')\n    sp2 = plt.subplot(132)\n    sp2.axis('off')\n    plt.title('Reconstruction')\n    sp3 = plt.subplot(133)\n    sp3.axis('off')\n    plt.title('Binarized')\n    sp1.imshow(np.reshape(y_test[j], (10, 10)), cmap=plt.cm.gray,\n               interpolation='nearest'),\n    sp2.imshow(np.reshape(y_pred[j], (10, 10)), cmap=plt.cm.gray,\n               interpolation='nearest'),\n    sp3.imshow(np.reshape(y_pred[j] > .5, (10, 10)), cmap=plt.cm.gray,\n               interpolation='nearest')\n    plt.savefig('miyawaki2008_reconstruction_%d' % i)\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}